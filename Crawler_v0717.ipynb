{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 內容區"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LU\\Desktop\\python\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['news_ID', 'hyperlink', 'content', 'name'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "tab=pd.read_excel('Sample_with_names.xlsx')\n",
    "print(tab.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#17\n",
    "def function(a) :\n",
    "    if 'nownews' in a:\n",
    "        return '00'\n",
    "    elif 'estate.ltn' in a:\n",
    "        return '16'\n",
    "    elif 'ltn' in a:\n",
    "        return '01'\n",
    "    elif 'chinatimes' in a:\n",
    "        return '02'\n",
    "    elif 'setn' in a:\n",
    "        return '03'\n",
    "    elif 'yahoo' in a:\n",
    "        return '04'\n",
    "    elif 'mirror' in a:\n",
    "        return '05'\n",
    "    elif 'ettoday' in a:\n",
    "        return '06'\n",
    "    elif 'cna' in a:\n",
    "        return '07'\n",
    "    elif 'money.udn' in a:\n",
    "        return '17'    \n",
    "    elif 'udn' in a:\n",
    "        return '08'\n",
    "    elif 'tvbs' in a:\n",
    "        return '09'\n",
    "    elif 'nextmag' in a:\n",
    "        return '10'\n",
    "    elif 'businesstoday' in a:\n",
    "        return '11'\n",
    "    elif 'hk01' in a:\n",
    "        return '12'\n",
    "    elif 'storm' in a:\n",
    "        return '13'\n",
    "    elif 'on.cc' in a:\n",
    "        return '14'\n",
    "    elif 'ebc'in a:\n",
    "        return '15'\n",
    "    #div,p分流\n",
    "tab['test1'] = tab.apply(lambda x: function(x.hyperlink), axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from requests.packages import urllib3\n",
    "urllib3.disable_warnings()\n",
    "headers={\n",
    "    'User-agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36'\n",
    "}\n",
    "from bs4 import BeautifulSoup\n",
    "def function(a):\n",
    "        r=requests.get(a,verify=False,headers=headers)\n",
    "        r.encoding='utf-8'\n",
    "        r=BeautifulSoup(r.text,'lxml') #以lxml為解碼器\n",
    "        r=r.find_all('title')\n",
    "        r='%s'*len(r) % tuple(r) \n",
    "        r=r.strip()\n",
    "        r1= re.compile(r'[<title> /]')\n",
    "        r= r1.sub('' ,r )\n",
    "        return r\n",
    "tab['title'] = tab.apply(lambda x: function(x.hyperlink), axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function(a) :\n",
    "    if '網址不存在' in a:\n",
    "        return 0\n",
    "    elif '網址錯誤' in a:\n",
    "        return 0\n",
    "    elif '網頁' in a:\n",
    "        return 0\n",
    "    elif len(a)<1:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "tab['test2'] = tab.apply(lambda x: function(x.title), axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function(a,b,c): \n",
    "    if c==1:\n",
    "        if b=='00': #Nownews\n",
    "            r=requests.get(a,verify=False,headers=headers)\n",
    "            r.encoding='utf-8'\n",
    "            r=BeautifulSoup(r.text,'lxml') #以lxml為解碼器\n",
    "            r=r.get_text() \n",
    "            r=r.split('(function (d, a, b, l, e, _)')[0].split('NOWnews關鍵字')[0].split('insertBefore(s, el)')[1].split('\\n大')[1]\n",
    "            r=r.strip()\n",
    "            r1= re.compile(r'[<p> /]')\n",
    "            r= r1.sub('' ,r )\n",
    "            return r\n",
    "        elif b=='01': #自由\n",
    "            r=requests.get(a,verify=False,headers=headers)\n",
    "            r.encoding='utf-8'\n",
    "            r=BeautifulSoup(r.text,'lxml') #以liml為解碼器\n",
    "            r=r.find_all('p')\n",
    "            r='%s'*len(r) % tuple(r)\n",
    "            r=r.strip()\n",
    "            r=r.split('報導')[1].split('<p class=\"appE1121\">')[0]\n",
    "            r1= re.compile(r'</p>')\n",
    "            r= r1.sub('' , r)\n",
    "            r1=re.compile(r'<p>')\n",
    "            r= r1.sub('' , r)\n",
    "            r1=re.compile(r'<p class=\"before_ir\" style=\"text-align: center; display: none;\">請繼續往下閱讀...<p class=\"after_ir\" style=\"display: none;\">')\n",
    "            r=r1.sub('',r)\n",
    "            return r\n",
    "        elif b=='16': #自由不動產\n",
    "            r=requests.get(a,verify=False,headers=headers)\n",
    "            r.encoding='utf-8'\n",
    "            r=BeautifulSoup(r.text,'lxml') #以liml為解碼器\n",
    "            r=r.find_all('p')\n",
    "            r='%s'*len(r) % tuple(r)\n",
    "            r=r.strip()\n",
    "            r=r.split('</span></span></p><p>')[1].split('</p><p><span class=\"ph_b ph_d1\">')[0]\n",
    "            r1= re.compile(r'</p>')\n",
    "            r= r1.sub('' , r)\n",
    "            r1=re.compile(r'<p>')\n",
    "            r= r1.sub('' , r)\n",
    "            r1=re.compile(r'<p class=\"before_ir\" style=\"text-align: center; display: none;\">請繼續往下閱讀...<p class=\"after_ir\" style=\"display: none;\">')\n",
    "            r=r1.sub('',r)\n",
    "            return r\n",
    "        elif b=='02' : #中時\n",
    "            r=requests.get(a,verify=False,headers=headers)\n",
    "            r.encoding='utf-8'\n",
    "            r=BeautifulSoup(r.text,'lxml') #以lxml為解碼器\n",
    "            r=r.find_all('p')\n",
    "            r='%s'*len(r) % tuple(r)\n",
    "            r=r.split('<strong>中時電子報對留言')[0]\n",
    "            r1= re.compile(r'</p>')\n",
    "            r= r1.sub('' , r)\n",
    "            r1= re.compile(r'<p>')\n",
    "            r= r1.sub('' , r)\n",
    "            return r\n",
    "        elif b=='03' : #三立\n",
    "            r=requests.get(a,verify=False,headers=headers)\n",
    "            r.encoding='utf-8'\n",
    "            r=BeautifulSoup(r.text,'lxml') #以lxml為解碼器\n",
    "            r=r.find_all('p')\n",
    "            r='%s'*len(r) % tuple(r)\n",
    "            r=r.strip()\n",
    "            r1= re.compile(r'[<p> / br]')\n",
    "            r= r1.sub('' ,r )\n",
    "            return r\n",
    "        elif b=='04' : #yahoo\n",
    "            r=requests.get(a,verify=False,headers=headers)\n",
    "            r.encoding='utf-8'\n",
    "            r=BeautifulSoup(r.text,'lxml') #以lxml為解碼器\n",
    "            r=r.find_all('p')\n",
    "            r='%s'*len(r) % tuple(r)\n",
    "            r0=r.strip()\n",
    "            r1=r0.split('br/')[1:]\n",
    "            r='%s'*len(r1) % tuple(r1)\n",
    "            return r\n",
    "        elif b=='05': #鏡報\n",
    "            r=requests.get(a,verify=False,headers=headers)\n",
    "            r.encoding='utf-8'\n",
    "            r=BeautifulSoup(r.text,'lxml') #以liml為解碼器\n",
    "            r=r.find_all('p')\n",
    "            r='%s'*len(r) % tuple(r)\n",
    "            r=r.split('</span>')[1].split('<p class=\"updated-time\">')[0]\n",
    "            r1= re.compile(r'</p>')\n",
    "            r= r1.sub('' , r)\n",
    "            r1= re.compile(r'<p>')\n",
    "            r= r1.sub('' , r)\n",
    "            return r\n",
    "        elif b=='06': #ETToday\n",
    "            r=requests.get(a,verify=False,headers=headers)\n",
    "            r.encoding='utf-8'\n",
    "            r=BeautifulSoup(r.text,'lxml') #以lxml為解碼器\n",
    "            r=r.find_all('p')\n",
    "            r='%s'*len(r) % tuple(r)\n",
    "            r=r.split('</p><p><span style=\"color' )[0]\n",
    "            r=r.strip()\n",
    "            r1= re.compile(r'[<p> /]')\n",
    "            r= r1.sub('' ,r )\n",
    "            return r\n",
    "        elif b=='07': #中央社\n",
    "            r=requests.get(a,verify=False,headers=headers)\n",
    "            r.encoding='utf-8'\n",
    "            r=BeautifulSoup(r.text,'lxml') #以lxml為解碼器\n",
    "            r=r.find_all('p')\n",
    "            r='%s'*len(r) % tuple(r)\n",
    "            r=r.split('電）' )[1].split('（編輯')[0]\n",
    "            r=r.strip()\n",
    "            r1= re.compile(r'[<p> /]')\n",
    "            r= r1.sub('' ,r )\n",
    "            return r\n",
    "        elif b=='17': #聯合報\n",
    "            r=requests.get(a,verify=False,headers=headers)\n",
    "            r.encoding='utf-8'\n",
    "            r=BeautifulSoup(r.text,'lxml') #以lxml為解碼器\n",
    "            r=r.find_all('p')\n",
    "            r='%s'*len(r) % tuple(r)\n",
    "            r=r.strip()\n",
    "            r=re.sub(r'[^\\u4e00-\\u9fa5]','',r)\n",
    "            return r        \n",
    "        elif b=='08': #聯合報\n",
    "            r=requests.get(a,verify=False,headers=headers)\n",
    "            r.encoding='utf-8'\n",
    "            r=BeautifulSoup(r.text,'lxml') #以lxml為解碼器\n",
    "            r='%s'*len(r) % tuple(r)\n",
    "            r=r.split('end of articles' )[0].split('<!-- content from cms -->')[1]\n",
    "            r=r.strip()\n",
    "            r=re.sub(r'[^\\u4e00-\\u9fa5]','',r)\n",
    "            return r\n",
    "        elif b=='09': #tvbs\n",
    "            r=requests.get(a,verify=False,headers=headers)\n",
    "            r.encoding='utf-8'\n",
    "            r=BeautifulSoup(r.text,'lxml') #以lxml為解碼器\n",
    "            r=r.find_all('p')\n",
    "            r='%s'*len(r) % tuple(r)\n",
    "            r=r.split('>大<')[1]\n",
    "            r=r.strip()\n",
    "            r1= re.compile(r'[<p> / br]')\n",
    "            r= r1.sub('' ,r )\n",
    "            return r\n",
    "        elif b=='10': #nextmag\n",
    "            r=requests.get(a,verify=False,headers=headers)\n",
    "            r.encoding='utf-8'\n",
    "            r=BeautifulSoup(r.text,'lxml') #以lxml為解碼器\n",
    "            r=r.find_all('p')\n",
    "            r='%s'*len(r) % tuple(r) \n",
    "            r=r.strip()\n",
    "            r1= re.compile(r'[<p> /]')\n",
    "            r= r1.sub('' ,r )\n",
    "            return r\n",
    "        elif b=='11': #businesstoday\n",
    "            r=requests.get(a,verify=False,headers=headers)\n",
    "            r.encoding='utf-8'\n",
    "            r=BeautifulSoup(r.text,'lxml') #以lxml為解碼器\n",
    "            r=r.find_all('p')\n",
    "            r='%s'*len(r) % tuple(r)\n",
    "            r=r.split('期</a>')[1].split('服務')[0]\n",
    "            r=r.strip()\n",
    "            r1= re.compile(r'[<p> /]')\n",
    "            r= r1.sub('' ,r )\n",
    "            return r\n",
    "        elif b=='12': #hk01\n",
    "            r=requests.get(a,verify=False,headers=headers)\n",
    "            r.encoding='utf-8'\n",
    "            r=BeautifulSoup(r.text,'lxml') #以lxml為解碼器\n",
    "            r=r.find_all('p')\n",
    "            r='%s'*len(r) % tuple(r)\n",
    "            r=r.split('註冊')[1].split('案件編號')[0]\n",
    "            r=r.strip()\n",
    "            r1= re.compile(r'[<p> /] ')\n",
    "            r= r1.sub('' ,r )\n",
    "            return r\n",
    "        elif b=='13': #風傳媒\n",
    "            r=requests.get(a,verify=False,headers=headers)\n",
    "            r.encoding='utf-8'\n",
    "            r=BeautifulSoup(r.text,'lxml') #以lxml為解碼器\n",
    "            r=r.find_all('p')\n",
    "            r='%s'*len(r) % tuple(r)\n",
    "            r=r.split('</p><p aid=\"61\">')[1].split('喜歡這篇文章嗎？')[0]\n",
    "            r=r.strip()\n",
    "            r1= re.compile(r'[<p> /] ')\n",
    "            r= r1.sub('' ,r )\n",
    "            return r\n",
    "        elif b=='14': #oncc\n",
    "            r=requests.get(a,verify=False,headers=headers)\n",
    "            r.encoding='utf-8'\n",
    "            r=BeautifulSoup(r.text,'lxml') #以lxml為解碼器\n",
    "            r=r.find_all('p')\n",
    "            r='%s'*len(r) % tuple(r)\n",
    "            r=r.strip()\n",
    "            r1= re.compile(r'[<p> / br] ')\n",
    "            r= r1.sub('' ,r )\n",
    "            return r\n",
    "        elif b=='15': #ebc\n",
    "            r=requests.get(a,verify=False,headers=headers)\n",
    "            r.encoding='utf-8'\n",
    "            r=BeautifulSoup(r.text,'lxml') #以lxml為解碼器\n",
    "            r=r.find_all('p')\n",
    "            r='%s'*len(r) % tuple(r)\n",
    "            r=r.strip()\n",
    "            r1= re.compile(r'[<p> / br]')\n",
    "            r= r1.sub('' ,r )\n",
    "            return r\n",
    "        else:\n",
    "            r=requests.get(a,verify=False,headers=headers)\n",
    "            r.encoding='utf-8'\n",
    "            r=BeautifulSoup(r.text,'lxml') #以lxml為解碼器\n",
    "            r=r.find_all('p')\n",
    "            r='%s'*len(r) % tuple(r) \n",
    "            r=r.strip()\n",
    "            r1= re.compile(r'[<p> /]')\n",
    "            r= r1.sub('' ,r )\n",
    "            return r\n",
    "    else: return 'error' \n",
    "#div,p分流\n",
    "tab['result'] = tab.apply(lambda x: function(x.hyperlink,x.test1,x.test2), axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab.to_csv('jade_v2.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 以上程式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 調校區"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab.result[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#爬文第一步&讓網站以為你是真人(User-agent的輸入)\n",
    "import requests\n",
    "from requests.packages import urllib3\n",
    "urllib3.disable_warnings()\n",
    "headers={\n",
    "    'User-agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36'\n",
    "}\n",
    "r=requests.get('https://news.ltn.com.tw/news/society/breakingnews/2810761',verify=False,headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "〕交通部觀光局茂林國家風景區管理處前處長許正雄被控收回扣案，地院調查喝花酒沒有對價關係，又查無貪污證據，並指廠商為脫罪而認罪協商，判決無罪，案經高雄高分院審理後，下午大逆轉改判有罪，許處有期徒刑10年2月、副處長楊國聰處則維持無罪判決。檢方指出，2011年間起，當時茂林風管處長的許正雄向承攬「六龜區及賽嘉樂園遊憩服務設施工程」委託設計監造劉姓建築師，索討決標金369萬的5％回扣，許前後共涉嫌索賄81萬元。此外，吳姓、林姓包商以1587萬元承攬「六龜遊客中心舊址遊憩服務設施整建工程」後，涉嫌設宴招待許和副處長楊國聰後，又轉往「香格里拉」酒店喝花酒，案經檢方偵結，劉、吳、林3人緩起訴處分，許、楊被依貪瀆罪起訴。高雄地院調查，劉、吳、林等人的認罪證詞，積極事證有待商榷；至於招待官員喝花酒的請客文化存在已久，雖有悖公務員守份自持官箴，但業者為期建立「特別私交」招待的飲宴行為，非等同貪污治罪條例所處罰的職務上行為，如果無法證明官商間有對價關係，充其量只是違反公務員行政倫理範疇，認定罪證不足。不過，二審合議庭則採信劉證詞，認定劉和許共見面5次，每次見面後，劉就去領錢，共行賄許25萬元，因此改判有罪，可上訴。\n"
     ]
    }
   ],
   "source": [
    "            r=BeautifulSoup(r.text,'lxml') #以liml為解碼器\n",
    "            r=r.find_all('p')\n",
    "            r='%s'*len(r) % tuple(r)\n",
    "            r=r.strip()\n",
    "            r=r.split('報導')[1].split('<p class=\"appE1121\">')[0]\n",
    "            r1= re.compile(r'</p>')\n",
    "            r= r1.sub('' , r)\n",
    "            r1=re.compile(r'<p>')\n",
    "            r= r1.sub('' , r)\n",
    "            r1=re.compile(r'<p class=\"before_ir\" style=\"text-align: center; display: none;\">請繼續往下閱讀...<p class=\"after_ir\" style=\"display: none;\">')\n",
    "            r=r1.sub('',r)\n",
    "            print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "台北地檢署偵辦國安特勤私菸案歷經個月多馬不停蹄抽絲剝繭調查今偵查終結將於點分開記者會說明因涉案人數眾多定調以嚴辦首謀從犯從輕為原則這波偵結對象是以在押首謀為主擬以貪汙治罪條例第條第項第款以公用運輸工具裝運違禁物品或漏稅物罪第條第項第款圖利罪起訴國安局及華航人員專案小組認定國安局少校吳宗憲張恒嘉與華航空品處前副總邱彰信協理于堯代理組長黃川禎等人涉犯貪汙治罪條例另買菸大戶上士駕駛劉尊彰民間人士李宗原等人涉違反稅捐稽徵法依法起訴其餘單純團購人員則另簽分偵辦月日總統蔡英文結束天自由民主永續之旅返台調查局以行政檢查方式攔查國安局官員隨團走私條菸金額高達萬元創桃園機場夾帶走私菸最大數量紀錄全案爆發後北檢立刻組成專案小組檢方先親赴吳張位於總統官邸附近侍衛室的宿舍辦公室調取電磁紀錄筆記本存摺等鞏固物證後再大規模約談訂購名單上的買家查明購菸目的屬自用代購轉售檢調清查華航是誰下令開放免稅菸品無限訂購幫助特勤人員逃漏稅月日約談華航前資深副總羅雅美空品處前副總邱彰信等人複訊後檢方命邱以萬元交保羅雅美則訊後請回華航空品處協理于堯坦承聽從邱指令辦事萬元交保為釐清華航機邊交貨的緣起和運作模式專案小組向上溯源傳喚空品處代理組長黃川禎空品處前後任經理沈珉等華航人員另傳喚透過總統府侍衛室及國安局訂私菸的民眾共餘人訊後全數請回最後階段檢調陸續清查訂購數百條的大戶約談華航年輕空服員白梓佑總統專機御廚田佳宜華航空品處資深員工陳穎彥徐世立等人訊後依違反稅捐稽徵法各以萬元至萬元交保台北地檢署圖本報資料照片台北地檢署圖本報資料照片台北地檢署圖本報資料照片勞退新制小攻略點我領取我的投資組合類股觀測即時排行即時選股即時走勢即時報價\n"
     ]
    }
   ],
   "source": [
    "r=BeautifulSoup(r.text,'lxml') #以liml為解碼器\n",
    "r=r.find_all('p')\n",
    "r='%s'*len(r) % tuple(r)\n",
    "r=r.strip()\n",
    "r=re.sub(r'[^\\u4e00-\\u9fa5]','',r)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "台中市台中市台中市鄭姓男子吸毒遭警方查獲供出上手是越南籍逃逸移工移工移工阮文全警方逮捕阮後又循線抓到印尼印尼印尼籍上游阿曼兩人均被檢方依毒品毒品毒品罪起訴台中地院認為兩人仗勢外籍移工身分在台灣販毒判阮三年十月徒刑阿曼四年四月徒刑宣告期滿驅逐出境判決指出鄭姓男子因涉毒品案遭警方逮捕向警方供出賣他毒品的是越南籍逃逸移工阮文全並同意配合辦案以手機與阮聯繫購買安毒阮信以為真再聯繫印尼籍上手阿曼阿曼將毒品交給阮後阮將毒品分裝十小包警方趁阮與鄭交易時當場人贓俱獲直售聯播阮被捕後向警方坦承毒品來源是阿曼警方今年六月分別在阿曼的南投住所與公司員工宿舍搜出安毒十一包並查扣分裝袋手機等物合議庭調查阮與阿曼兩人非至親不會花費心思規避查緝認定兩人購入的毒品價位比售出的價位還要低可預見兩人從中賺取差價不法牟利考量阮為越南籍逃逸移工阿曼為印尼籍合法移工兩人販毒危害國民健康與社會治安宣告執行期滿後驅逐出境\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "r=BeautifulSoup(r.text,'lxml') #以liml為解碼器\n",
    "r='%s'*len(r) % tuple(r)\n",
    "r=r.split('end of articles' )[0].split('<!-- content from cms -->')[1]\n",
    "r=r.strip()\n",
    "r=re.sub(r'[^\\u4e00-\\u9fa5]','',r)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-0d6c19f25485>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mbs4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'lxml'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#以liml為解碼器\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'p'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'%s'\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "r=BeautifulSoup(r.text,'lxml') #以liml為解碼器\n",
    "r=r.find_all('p')\n",
    "r='%s'*len(r) % tuple(r)\n",
    "r=r.split('</span>')[1].split('<p class=\"updated-time\">')[0]\n",
    "r1= re.compile(r'</p>')\n",
    "r= r1.sub('' , r)\n",
    "r1= re.compile(r'<p>')\n",
    "r= r1.sub('' , r)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "位於桃園市桃園區春日路的建案「銘曜高尚」近日驚傳建商落跑，留下鉅額債務給已購的買方，有消費者出面指控，建商一屋二賣，欺騙大眾，而記者致電銘耀建設負責人，電話號碼已經暫停使用。</p><p> </p><p>「銘曜高尚」鄰近家樂福春日店、Uniqlo，週邊生活機能完整，也有國中小學區，加上該案主打4米2+3米錯層式設計，小宅的價錢就可買到高坪效，因此吸引許多自住族青睞，而且成屋銷售，讓大家看得到摸得到，沒想到還是發生建商落跑憾事。</p><p> </p><p>觀察該案官方粉絲團，最新發文停留在去年12月21日，當時還舉行聖誕抽獎活動，完全看不出異樣。然而受害者出面指控，不僅「銘曜高尚」一屋二賣，另一個在桃園區泰昌街的案子也是同樣狀況。目前「銘曜高尚」大樓已經被受害者張貼「黑心建商」、「邱阿水聯合詐欺」等布條，據了解，建商超貸3億元，如果消費者想要過戶，必須得先償還債務塗銷貸款。</p><p> </p><p>據了解，此次是碁曜機構董事長邱水成及其妻子邱秀芬遭指控詐欺落跑，而該案「銘曜高尚」主要由兒子邱俊銘負責，如今父母疑似出事落跑，兒子手機也停話未回應，此外，據相關人士私下透露，邱水成女兒名下的擎亞建設似乎也出現倒閉危機。</p><p> </p><p>住展雜誌企研室經理何世昌指出，購買預售屋擁有相對風險，建議消費者在篩選建商時，除了建商至少要營運超過五年、手上建案10個以上，才能確保建商足夠的財力。\n"
     ]
    }
   ],
   "source": [
    "#自由時報內容\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "r.encoding='utf-8'\n",
    "r=BeautifulSoup(r.text,'lxml') #以liml為解碼器\n",
    "r=r.find_all('p')\n",
    "r='%s'*len(r) % tuple(r)\n",
    "r=r.split('</span></span></p><p>')[1].split('</p><p><span class=\"ph_b ph_d1\">')[0]\n",
    "r=re.sub(r'[^\\u4e00-u9fa5]','',r)\n",
    "print(r)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
