{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 內容區"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LU\\Desktop\\python\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['news_ID', 'hyperlink', 'content', 'name'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "tab=pd.read_excel('Sample_with_names.xlsx')\n",
    "print(tab.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function(a) :\n",
    "    if 'nownews' in a:\n",
    "        return '00'\n",
    "    elif 'estate.ltn' in a:\n",
    "        return '16'\n",
    "    elif 'ltn' in a:\n",
    "        return '01'\n",
    "    elif 'chinatimes' in a:\n",
    "        return '02'\n",
    "    elif 'setn' in a:\n",
    "        return '03'\n",
    "    elif 'yahoo' in a:\n",
    "        return '04'\n",
    "    elif 'mirror' in a:\n",
    "        return '05'\n",
    "    elif 'ettoday' in a:\n",
    "        return '06'\n",
    "    elif 'cna' in a:\n",
    "        return '07'\n",
    "    elif 'udn' in a:\n",
    "        return '08'\n",
    "    elif 'tvbs' in a:\n",
    "        return '09'\n",
    "    elif 'nextmag' in a:\n",
    "        return '10'\n",
    "    elif 'businesstoday' in a:\n",
    "        return '11'\n",
    "    elif 'hk01' in a:\n",
    "        return '12'\n",
    "    elif 'storm' in a:\n",
    "        return '13'\n",
    "    elif 'on.cc' in a:\n",
    "        return '14'\n",
    "    elif 'ebc'in a:\n",
    "        return '15'\n",
    "    #div,p分流\n",
    "tab['test1'] = tab.apply(lambda x: function(x.hyperlink), axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from requests.packages import urllib3\n",
    "urllib3.disable_warnings()\n",
    "headers={\n",
    "    'User-agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36'\n",
    "}\n",
    "from bs4 import BeautifulSoup\n",
    "def function(a):\n",
    "        r=requests.get(a,verify=False,headers=headers)\n",
    "        r.encoding='utf-8'\n",
    "        r=BeautifulSoup(r.text,'lxml') #以lxml為解碼器\n",
    "        r=r.find_all('title')\n",
    "        r='%s'*len(r) % tuple(r) \n",
    "        r=r.strip()\n",
    "        r1= re.compile(r'[<title> /]')\n",
    "        r= r1.sub('' ,r )\n",
    "        return r\n",
    "tab['title'] = tab.apply(lambda x: function(x.hyperlink), axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function(a) :\n",
    "    if '網址不存在' in a:\n",
    "        return 0\n",
    "    if '網址錯誤' in a:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "tab['test2'] = tab.apply(lambda x: function(x.title), axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function(a,b,c): \n",
    "    if c==1:\n",
    "        if b=='00': #Nownews\n",
    "            r=requests.get(a,verify=False,headers=headers)\n",
    "            r.encoding='utf-8'\n",
    "            r=BeautifulSoup(r.text,'lxml') #以lxml為解碼器\n",
    "            r=r.get_text() \n",
    "            r=r.split('(function (d, a, b, l, e, _)')[0].split('NOWnews關鍵字')[0].split('insertBefore(s, el)')[1].split('\\n大')[1]\n",
    "            r=r.strip()\n",
    "            r1= re.compile(r'[<p> /]')\n",
    "            r= r1.sub('' ,r )\n",
    "            return r\n",
    "        elif b=='01': #自由\n",
    "            r=requests.get(a,verify=False,headers=headers)\n",
    "            r.encoding='utf-8'\n",
    "            r=BeautifulSoup(r.text,'lxml') #以liml為解碼器\n",
    "            r=r.find_all('p')\n",
    "            r='%s'*len(r) % tuple(r)\n",
    "            r=r.strip()\n",
    "            r=r.split('報導')[1].split('<p class=\"appE1121\">')[0]\n",
    "            r1= re.compile(r'</p>')\n",
    "            r= r1.sub('' , r)\n",
    "            r1=re.compile(r'<p>')\n",
    "            r= r1.sub('' , r)\n",
    "            r1=re.compile(r'<p class=\"before_ir\" style=\"text-align: center; display: none;\">請繼續往下閱讀...<p class=\"after_ir\" style=\"display: none;\">')\n",
    "            r=r1.sub('',r)\n",
    "        elif b=='16': #自由不動產\n",
    "            r=requests.get(a,verify=False,headers=headers)\n",
    "            r.encoding='utf-8'\n",
    "            r=BeautifulSoup(r.text,'lxml') #以liml為解碼器\n",
    "            r=r.find_all('p')\n",
    "            r='%s'*len(r) % tuple(r)\n",
    "            r=r.strip()\n",
    "            r=r.split('</span></span></p><p>')[1].split('</p><p><span class=\"ph_b ph_d1\">')[0]\n",
    "            r1= re.compile(r'</p>')\n",
    "            r= r1.sub('' , r)\n",
    "            r1=re.compile(r'<p>')\n",
    "            r= r1.sub('' , r)\n",
    "            r1=re.compile(r'<p class=\"before_ir\" style=\"text-align: center; display: none;\">請繼續往下閱讀...<p class=\"after_ir\" style=\"display: none;\">')\n",
    "            r=r1.sub('',r)\n",
    "        elif b=='02' : #中時\n",
    "            r=requests.get(a,verify=False,headers=headers)\n",
    "            r.encoding='utf-8'\n",
    "            r=BeautifulSoup(r.text,'lxml') #以lxml為解碼器\n",
    "            r=r.find_all('p')\n",
    "            r='%s'*len(r) % tuple(r)\n",
    "            r=r.split('<strong>中時電子報對留言')[0]\n",
    "            r1= re.compile(r'</p>')\n",
    "            r= r1.sub('' , r)\n",
    "            r1= re.compile(r'<p>')\n",
    "            r= r1.sub('' , r)\n",
    "            return r\n",
    "        elif b=='03' : #三立\n",
    "            r=requests.get(a,verify=False,headers=headers)\n",
    "            r.encoding='utf-8'\n",
    "            r=BeautifulSoup(r.text,'lxml') #以lxml為解碼器\n",
    "            r=r.find_all('p')\n",
    "            r='%s'*len(r) % tuple(r)\n",
    "            r=r.strip()\n",
    "            r1= re.compile(r'[<p> / br]')\n",
    "            r= r1.sub('' ,r )\n",
    "            return r\n",
    "        elif b=='04' : #yahoo\n",
    "            r=requests.get(a,verify=False,headers=headers)\n",
    "            r.encoding='utf-8'\n",
    "            r=BeautifulSoup(r.text,'lxml') #以lxml為解碼器\n",
    "            r=r.find_all('p')\n",
    "            r='%s'*len(r) % tuple(r)\n",
    "            r0=r.strip()\n",
    "            r1=r0.split('br/')[1:]\n",
    "            r='%s'*len(r1) % tuple(r1)\n",
    "            return r\n",
    "        elif b=='05': #鏡報\n",
    "            r=requests.get(a,verify=False,headers=headers)\n",
    "            r.encoding='utf-8'\n",
    "            r=BeautifulSoup(r.text,'lxml') #以liml為解碼器\n",
    "            r=r.find_all('p')\n",
    "            r='%s'*len(r) % tuple(r)\n",
    "            r=r.split('</span>')[1].split('<p class=\"updated-time\">')[0]\n",
    "            r1= re.compile(r'</p>')\n",
    "            r= r1.sub('' , r)\n",
    "            r1= re.compile(r'<p>')\n",
    "            r= r1.sub('' , r)\n",
    "            return r\n",
    "        elif b=='06': #ETToday\n",
    "            r=requests.get(a,verify=False,headers=headers)\n",
    "            r.encoding='utf-8'\n",
    "            r=BeautifulSoup(r.text,'lxml') #以lxml為解碼器\n",
    "            r=r.find_all('p')\n",
    "            r='%s'*len(r) % tuple(r)\n",
    "            r=r.split('</p><p><span style=\"color' )[0]\n",
    "            r=r.strip()\n",
    "            r1= re.compile(r'[<p> /]')\n",
    "            r= r1.sub('' ,r )\n",
    "            return r\n",
    "        elif b=='07': #中央社\n",
    "            r=requests.get(a,verify=False,headers=headers)\n",
    "            r.encoding='utf-8'\n",
    "            r=BeautifulSoup(r.text,'lxml') #以lxml為解碼器\n",
    "            r=r.find_all('p')\n",
    "            r='%s'*len(r) % tuple(r)\n",
    "            r=r.split('電）' )[1].split('（編輯')[0]\n",
    "            r=r.strip()\n",
    "            r1= re.compile(r'[<p> /]')\n",
    "            r= r1.sub('' ,r )\n",
    "            return r\n",
    "        elif b=='08': #聯合報\n",
    "            r=requests.get(a,verify=False,headers=headers)\n",
    "            r.encoding='utf-8'\n",
    "            r=BeautifulSoup(r.text,'lxml') #以lxml為解碼器\n",
    "            r=r.find_all('p')\n",
    "            r='%s'*len(r) % tuple(r)\n",
    "            r=r.split('<p style=\"margin-bottom' )[0]\n",
    "            r=r.strip()\n",
    "            r1= re.compile(r'[<p> / ahref=\"searchtagging2]')\n",
    "            r= r1.sub('' ,r )\n",
    "            return r\n",
    "        elif b=='09': #tvbs\n",
    "            r=requests.get(a,verify=False,headers=headers)\n",
    "            r.encoding='utf-8'\n",
    "            r=BeautifulSoup(r.text,'lxml') #以lxml為解碼器\n",
    "            r=r.find_all('p')\n",
    "            r='%s'*len(r) % tuple(r)\n",
    "            r=r.split('>大<')[1]\n",
    "            r=r.strip()\n",
    "            r1= re.compile(r'[<p> / br]')\n",
    "            r= r1.sub('' ,r )\n",
    "            return r\n",
    "        elif b=='10': #nextmag\n",
    "            r=requests.get(a,verify=False,headers=headers)\n",
    "            r.encoding='utf-8'\n",
    "            r=BeautifulSoup(r.text,'lxml') #以lxml為解碼器\n",
    "            r=r.find_all('p')\n",
    "            r='%s'*len(r) % tuple(r) \n",
    "            r=r.strip()\n",
    "            r1= re.compile(r'[<p> /]')\n",
    "            r= r1.sub('' ,r )\n",
    "            return r\n",
    "        elif b=='11': #businesstoday\n",
    "            r=requests.get(a,verify=False,headers=headers)\n",
    "            r.encoding='utf-8'\n",
    "            r=BeautifulSoup(r.text,'lxml') #以lxml為解碼器\n",
    "            r=r.find_all('p')\n",
    "            r='%s'*len(r) % tuple(r)\n",
    "            r=r.split('期</a>')[1].split('服務')[0]\n",
    "            r=r.strip()\n",
    "            r1= re.compile(r'[<p> /]')\n",
    "            r= r1.sub('' ,r )\n",
    "            return r\n",
    "        elif b=='12': #hk01\n",
    "            r=requests.get(a,verify=False,headers=headers)\n",
    "            r.encoding='utf-8'\n",
    "            r=BeautifulSoup(r.text,'lxml') #以lxml為解碼器\n",
    "            r=r.find_all('p')\n",
    "            r='%s'*len(r) % tuple(r)\n",
    "            r=r.split('註冊')[1].split('案件編號')[0]\n",
    "            r=r.strip()\n",
    "            r1= re.compile(r'[<p> /] ')\n",
    "            r= r1.sub('' ,r )\n",
    "            return r\n",
    "        elif b=='13': #風傳媒\n",
    "            r=requests.get(a,verify=False,headers=headers)\n",
    "            r.encoding='utf-8'\n",
    "            r=BeautifulSoup(r.text,'lxml') #以lxml為解碼器\n",
    "            r=r.find_all('p')\n",
    "            r='%s'*len(r) % tuple(r)\n",
    "            r=r.split('</p><p aid=\"61\">')[1].split('喜歡這篇文章嗎？')[0]\n",
    "            r=r.strip()\n",
    "            r1= re.compile(r'[<p> /] ')\n",
    "            r= r1.sub('' ,r )\n",
    "            return r\n",
    "        elif b=='14': #oncc\n",
    "            r=requests.get(a,verify=False,headers=headers)\n",
    "            r.encoding='utf-8'\n",
    "            r=BeautifulSoup(r.text,'lxml') #以lxml為解碼器\n",
    "            r=r.find_all('p')\n",
    "            r='%s'*len(r) % tuple(r)\n",
    "            r=r.strip()\n",
    "            r1= re.compile(r'[<p> / br] ')\n",
    "            r= r1.sub('' ,r )\n",
    "            return r\n",
    "        elif b=='15': #ebc\n",
    "            r=requests.get(a,verify=False,headers=headers)\n",
    "            r.encoding='utf-8'\n",
    "            r=BeautifulSoup(r.text,'lxml') #以lxml為解碼器\n",
    "            r=r.find_all('p')\n",
    "            r='%s'*len(r) % tuple(r)\n",
    "            r=r.strip()\n",
    "            r1= re.compile(r'[<p> / br]')\n",
    "            r= r1.sub('' ,r )\n",
    "            return r\n",
    "        else:\n",
    "            r=requests.get(a,verify=False,headers=headers)\n",
    "            r.encoding='utf-8'\n",
    "            r=BeautifulSoup(r.text,'lxml') #以lxml為解碼器\n",
    "            r=r.find_all('p')\n",
    "            r='%s'*len(r) % tuple(r) \n",
    "            r=r.strip()\n",
    "            r1= re.compile(r'[<p> /]')\n",
    "            r= r1.sub('' ,r )\n",
    "            return r\n",
    "    else: return 'error' \n",
    "#div,p分流\n",
    "tab['result'] = tab.apply(lambda x: function(x.hyperlink,x.test1,x.test2), axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab.to_csv('jade_v2.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 以上程式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 調校區"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://news.ltn.com.tw/news/life/breakingnews/2853433'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tab.hyperlink[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#爬文第一步&讓網站以為你是真人(User-agent的輸入)\n",
    "import requests\n",
    "from requests.packages import urllib3\n",
    "urllib3.disable_warnings()\n",
    "headers={\n",
    "    'User-agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36'\n",
    "}\n",
    "r=requests.get('https://www.mirrormedia.mg/story/20190131soc001',verify=False,headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "r=BeautifulSoup(r.text,'lxml') #以liml為解碼器\n",
    "r=r.find_all('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "前國防部政治作戰總隊總隊長王光遠將軍的妻子楚瑞芳，和另名男子彭振源，2人自稱是華固建設公司高層，用將出任下任董事長的名義，以華固欲整合台北市和平東路、樂業路口周邊的一塊土地為由募資，吸引二十多人拿錢投資，金額近億元，其中1名林姓房地產商察覺有異，自己訪查發現，2人根本與華固建設沒有關係，華固同時也發出律師函澄清絕無此事，林男才驚覺遭騙。這名將軍夫人叫楚瑞芳（65歲），她是政治作戰學校政治系24期畢業，其夫王光遠跟她是軍校同班同學，王從國防部政治總隊少將總隊長退伍，王對太極鑽研頗深，經常獲邀表演太極，曾任中華熊氏太極拳總會理事。將軍夫人又是退伍軍官怎麼會變成騙子？事情發生在2016年5月底，楚女和另名男子彭振源，透過林男的一名交情頗深的老同事王澤生找上他，聲稱她們2人是華固建設公司高層，與華固董座鍾榮昌是多年好友，私交甚篤，楚女甚至強調她因為整合土地成功，未來將是下一任華固建設董座，但因整合土地仍需要金錢上的奧援擺平居民，需要林男「挹注資金」。林男當時質疑，華固這麼大的公司應該不會缺資金整合土地，怎麼可能找上他這種小地產商，但王澤生一再跟他保證，曾經跟鍾榮昌本人當面確認過該起土地整合案，加上楚女不斷強調他的將軍夫人身分，與王金平、宋楚瑜等黨政高層都很熟悉，林男上網查詢，也確認楚女的將軍夫人身分。楚女當時還強調，之所以這樣做，是因為鍾榮昌本人在外私設公司，欲以私設公司整合土地，然後回賣給華固建設來套利，因此華固不會有任何金流流出，以防有掏空的嫌疑，所以才會由她出面擔任「影舞者」的角色。林男聽完後不疑有他，又有老同事保證，從5月底至12月初，陸續交付楚女約1,000萬元。但林男自5月底挹注資金開始，一直到了12月這段期間，他頻頻覺得有異，不斷起疑，林男後來根據楚女提供的地號將土地謄本列出來，直接到了楚女所宣稱整合的路段查詢，並挨家挨戶的詢問附近商家及住戶，得到的消息都是有很多建商有意思整合，但並沒有確切的說是哪家建設公司，林男說：「若是真的整合成功，也需要10年、20年的時間，根本不是楚女說的只剩一戶還沒給錢之類的情形。」林男驚覺遭騙。\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "r=BeautifulSoup(r.text,'lxml') #以liml為解碼器\n",
    "r=r.find_all('p')\n",
    "r='%s'*len(r) % tuple(r)\n",
    "r=r.split('</span>')[1].split('<p class=\"updated-time\">')[0]\n",
    "r1= re.compile(r'</p>')\n",
    "r= r1.sub('' , r)\n",
    "r1= re.compile(r'<p>')\n",
    "r= r1.sub('' , r)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "位於桃園市桃園區春日路的建案「銘曜高尚」近日驚傳建商落跑，留下鉅額債務給已購的買方，有消費者出面指控，建商一屋二賣，欺騙大眾，而記者致電銘耀建設負責人，電話號碼已經暫停使用。</p><p> </p><p>「銘曜高尚」鄰近家樂福春日店、Uniqlo，週邊生活機能完整，也有國中小學區，加上該案主打4米2+3米錯層式設計，小宅的價錢就可買到高坪效，因此吸引許多自住族青睞，而且成屋銷售，讓大家看得到摸得到，沒想到還是發生建商落跑憾事。</p><p> </p><p>觀察該案官方粉絲團，最新發文停留在去年12月21日，當時還舉行聖誕抽獎活動，完全看不出異樣。然而受害者出面指控，不僅「銘曜高尚」一屋二賣，另一個在桃園區泰昌街的案子也是同樣狀況。目前「銘曜高尚」大樓已經被受害者張貼「黑心建商」、「邱阿水聯合詐欺」等布條，據了解，建商超貸3億元，如果消費者想要過戶，必須得先償還債務塗銷貸款。</p><p> </p><p>據了解，此次是碁曜機構董事長邱水成及其妻子邱秀芬遭指控詐欺落跑，而該案「銘曜高尚」主要由兒子邱俊銘負責，如今父母疑似出事落跑，兒子手機也停話未回應，此外，據相關人士私下透露，邱水成女兒名下的擎亞建設似乎也出現倒閉危機。</p><p> </p><p>住展雜誌企研室經理何世昌指出，購買預售屋擁有相對風險，建議消費者在篩選建商時，除了建商至少要營運超過五年、手上建案10個以上，才能確保建商足夠的財力。\n"
     ]
    }
   ],
   "source": [
    "#自由時報內容\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "r.encoding='utf-8'\n",
    "r=BeautifulSoup(r.text,'lxml') #以liml為解碼器\n",
    "r=r.find_all('p')\n",
    "r='%s'*len(r) % tuple(r)\n",
    "r=r.split('</span></span></p><p>')[1].split('</p><p><span class=\"ph_b ph_d1\">')[0]\n",
    "print(r)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
