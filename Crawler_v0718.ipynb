{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 內容區"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LU\\Desktop\\python\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['news_ID', 'hyperlink', 'content', 'name'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "tab=pd.read_csv('Sample_with_half_half.csv')\n",
    "print(tab.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#17\n",
    "def function(a) :\n",
    "    if 'nownews' in a:\n",
    "        return '00'\n",
    "    elif 'estate.ltn' in a:\n",
    "        return '16'\n",
    "    elif 'ltn' in a:\n",
    "        return '01'\n",
    "    elif 'chinatimes' in a:\n",
    "        return '02'\n",
    "    elif 'setn' in a:\n",
    "        return '03'\n",
    "    elif 'yahoo' in a:\n",
    "        return '04'\n",
    "    elif 'mirror' in a:\n",
    "        return '05'\n",
    "    elif 'ettoday' in a:\n",
    "        return '06'\n",
    "    elif 'cna' in a:\n",
    "        return '07'\n",
    "    elif 'money.udn' in a:\n",
    "        return '17'    \n",
    "    elif 'udn' in a:\n",
    "        return '08'\n",
    "    elif 'tvbs' in a:\n",
    "        return '09'\n",
    "    elif 'nextmag' in a:\n",
    "        return '10'\n",
    "    elif 'businesstoday' in a:\n",
    "        return '11'\n",
    "    elif 'hk01' in a:\n",
    "        return '12'\n",
    "    elif 'storm' in a:\n",
    "        return '13'\n",
    "    elif 'on.cc' in a:\n",
    "        return '14'\n",
    "    elif 'ebc'in a:\n",
    "        return '15'\n",
    "    elif 'mops.twse' in a:\n",
    "        return '18'\n",
    "    #div,p分流\n",
    "tab['test1'] = tab.apply(lambda x: function(x.hyperlink), axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from requests.packages import urllib3\n",
    "urllib3.disable_warnings()\n",
    "headers={\n",
    "    'User-agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36'\n",
    "}\n",
    "from bs4 import BeautifulSoup\n",
    "def function(a):\n",
    "        r=requests.get(a,verify=False,headers=headers)\n",
    "        r.encoding='utf-8'\n",
    "        r=BeautifulSoup(r.text,'lxml') #以lxml為解碼器\n",
    "        r=r.find_all('title')\n",
    "        r='%s'*len(r) % tuple(r) \n",
    "        r=r.strip()\n",
    "        r1= re.compile(r'[<title> /]')\n",
    "        r= r1.sub('' ,r )\n",
    "        return r\n",
    "tab['title'] = tab.apply(lambda x: function(x.hyperlink), axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function(a,b) :\n",
    "    if '網址不存在' in a:\n",
    "        return 0\n",
    "    elif '網址錯誤' in a:\n",
    "        return 0\n",
    "    elif '網頁' in a:\n",
    "        return 0\n",
    "    elif len(a)<1:\n",
    "        return 0\n",
    "    elif b==18:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "tab['test2'] = tab.apply(lambda x: function(x.title,x.test1), axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function(a,b,c): \n",
    "    if c==1:\n",
    "        if b=='00': #Nownews\n",
    "            r=requests.get(a,verify=False,headers=headers)\n",
    "            r.encoding='utf-8'\n",
    "            r=BeautifulSoup(r.text,'lxml') #以lxml為解碼器\n",
    "            r=r.get_text() \n",
    "            r=r.split('(function (d, a, b, l, e, _)')[0].split('NOWnews關鍵字')[0].split('insertBefore(s, el)')[1].split('\\n大')[1]\n",
    "            r=r.strip()\n",
    "            r1= re.compile(r'[<p> /]')\n",
    "            r= r1.sub('' ,r )\n",
    "            return r\n",
    "        elif b=='01': #自由\n",
    "            r=requests.get(a,verify=False,headers=headers)\n",
    "            r.encoding='utf-8'\n",
    "            r=BeautifulSoup(r.text,'lxml') #以liml為解碼器\n",
    "            r=r.find_all('p')\n",
    "            r='%s'*len(r) % tuple(r)\n",
    "            r=r.strip()\n",
    "            r=r.split('報導')[1].split('<p class=\"appE1121\">')[0]\n",
    "            r1= re.compile(r'</p>')\n",
    "            r= r1.sub('' , r)\n",
    "            r1=re.compile(r'<p>')\n",
    "            r= r1.sub('' , r)\n",
    "            r1=re.compile(r'<p class=\"before_ir\" style=\"text-align: center; display: none;\">請繼續往下閱讀...<p class=\"after_ir\" style=\"display: none;\">')\n",
    "            r=r1.sub('',r)\n",
    "            return r\n",
    "        elif b=='16': #自由不動產\n",
    "            r=requests.get(a,verify=False,headers=headers)\n",
    "            r.encoding='utf-8'\n",
    "            r=BeautifulSoup(r.text,'lxml') #以liml為解碼器\n",
    "            r=r.find_all('p')\n",
    "            r='%s'*len(r) % tuple(r)\n",
    "            r=r.strip()\n",
    "            r=r.split('</span></span></p><p>')[1].split('</p><p><span class=\"ph_b ph_d1\">')[0]\n",
    "            r1= re.compile(r'</p>')\n",
    "            r= r1.sub('' , r)\n",
    "            r1=re.compile(r'<p>')\n",
    "            r= r1.sub('' , r)\n",
    "            r1=re.compile(r'<p class=\"before_ir\" style=\"text-align: center; display: none;\">請繼續往下閱讀...<p class=\"after_ir\" style=\"display: none;\">')\n",
    "            r=r1.sub('',r)\n",
    "            return r\n",
    "        elif b=='02' : #中時\n",
    "            r=requests.get(a,verify=False,headers=headers)\n",
    "            r.encoding='utf-8'\n",
    "            r=BeautifulSoup(r.text,'lxml') #以lxml為解碼器\n",
    "            r=r.find_all('p')\n",
    "            r='%s'*len(r) % tuple(r)\n",
    "            r=r.split('<strong>中時電子報對留言')[0]\n",
    "            r1= re.compile(r'</p>')\n",
    "            r= r1.sub('' , r)\n",
    "            r1= re.compile(r'<p>')\n",
    "            r= r1.sub('' , r)\n",
    "            return r\n",
    "        elif b=='03' : #三立\n",
    "            r=requests.get(a,verify=False,headers=headers)\n",
    "            r.encoding='utf-8'\n",
    "            r=BeautifulSoup(r.text,'lxml') #以lxml為解碼器\n",
    "            r=r.find_all('p')\n",
    "            r='%s'*len(r) % tuple(r)\n",
    "            r=r.strip()\n",
    "            r1= re.compile(r'[<p> / br]')\n",
    "            r= r1.sub('' ,r )\n",
    "            return r\n",
    "        elif b=='04' : #yahoo\n",
    "            r=requests.get(a,verify=False,headers=headers)\n",
    "            r.encoding='utf-8'\n",
    "            r=BeautifulSoup(r.text,'lxml') #以lxml為解碼器\n",
    "            r=r.find_all('p')\n",
    "            r='%s'*len(r) % tuple(r)\n",
    "            r0=r.strip()\n",
    "            r1=r0.split('br/')[1:]\n",
    "            r='%s'*len(r1) % tuple(r1)\n",
    "            return r\n",
    "        elif b=='05': #鏡報\n",
    "            r=requests.get(a,verify=False,headers=headers)\n",
    "            r.encoding='utf-8'\n",
    "            r=BeautifulSoup(r.text,'lxml') #以liml為解碼器\n",
    "            r=r.find_all('p')\n",
    "            r='%s'*len(r) % tuple(r)\n",
    "            r=r.split('</span>')[1].split('<p class=\"updated-time\">')[0]\n",
    "            r1= re.compile(r'</p>')\n",
    "            r= r1.sub('' , r)\n",
    "            r1= re.compile(r'<p>')\n",
    "            r= r1.sub('' , r)\n",
    "            return r\n",
    "        elif b=='06': #ETToday\n",
    "            r=requests.get(a,verify=False,headers=headers)\n",
    "            r.encoding='utf-8'\n",
    "            r=BeautifulSoup(r.text,'lxml') #以lxml為解碼器\n",
    "            r=r.find_all('p')\n",
    "            r='%s'*len(r) % tuple(r)\n",
    "            r=r.split('</p><p><span style=\"color' )[0]\n",
    "            r=r.strip()\n",
    "            r1= re.compile(r'[<p> /]')\n",
    "            r= r1.sub('' ,r )\n",
    "            return r\n",
    "        elif b=='07': #中央社\n",
    "            r=requests.get(a,verify=False,headers=headers)\n",
    "            r.encoding='utf-8'\n",
    "            r=BeautifulSoup(r.text,'lxml') #以lxml為解碼器\n",
    "            r=r.find_all('p')\n",
    "            r='%s'*len(r) % tuple(r)\n",
    "            r=r.split('電）' )[1].split('（編輯')[0]\n",
    "            r=r.strip()\n",
    "            r1= re.compile(r'[<p> /]')\n",
    "            r= r1.sub('' ,r )\n",
    "            return r\n",
    "        elif b=='17': #聯合報\n",
    "            r=requests.get(a,verify=False,headers=headers)\n",
    "            r.encoding='utf-8'\n",
    "            r=BeautifulSoup(r.text,'lxml') #以lxml為解碼器\n",
    "            r=r.find_all('p')\n",
    "            r='%s'*len(r) % tuple(r)\n",
    "            r=r.strip()\n",
    "            r=re.sub(r'[^\\u4e00-\\u9fa5]','',r)\n",
    "            return r        \n",
    "        elif b=='08': #聯合報\n",
    "            r=requests.get(a,verify=False,headers=headers)\n",
    "            r.encoding='utf-8'\n",
    "            r=BeautifulSoup(r.text,'lxml') #以lxml為解碼器\n",
    "            r='%s'*len(r) % tuple(r)\n",
    "            r=r.split('end of articles' )[0].split('<!-- content from cms -->')[1]\n",
    "            r=r.strip()\n",
    "            r=re.sub(r'[^\\u4e00-\\u9fa5]','',r)\n",
    "            return r\n",
    "        elif b=='09': #tvbs\n",
    "            r=requests.get(a,verify=False,headers=headers)\n",
    "            r.encoding='utf-8'\n",
    "            r=BeautifulSoup(r.text,'lxml') #以lxml為解碼器\n",
    "            r=r.find_all('p')\n",
    "            r='%s'*len(r) % tuple(r)\n",
    "            r=r.split('>大<')[1]\n",
    "            r=r.strip()\n",
    "            r1= re.compile(r'[<p> / br]')\n",
    "            r= r1.sub('' ,r )\n",
    "            return r\n",
    "        elif b=='10': #nextmag\n",
    "            r=requests.get(a,verify=False,headers=headers)\n",
    "            r.encoding='utf-8'\n",
    "            r=BeautifulSoup(r.text,'lxml') #以lxml為解碼器\n",
    "            r=r.find_all('p')\n",
    "            r='%s'*len(r) % tuple(r) \n",
    "            r=r.strip()\n",
    "            r1= re.compile(r'[<p> /]')\n",
    "            r= r1.sub('' ,r )\n",
    "            return r\n",
    "        elif b=='11': #businesstoday\n",
    "            r=requests.get(a,verify=False,headers=headers)\n",
    "            r.encoding='utf-8'\n",
    "            r=BeautifulSoup(r.text,'lxml') #以lxml為解碼器\n",
    "            r=r.find_all('p')\n",
    "            r='%s'*len(r) % tuple(r) \n",
    "            r=r.strip()\n",
    "            r1= re.compile(r'[<p> /]')\n",
    "            r= r1.sub('' ,r )\n",
    "            return r\n",
    "        elif b=='12': #hk01\n",
    "            r=requests.get(a,verify=False,headers=headers)\n",
    "            r.encoding='utf-8'\n",
    "            r=BeautifulSoup(r.text,'lxml') #以lxml為解碼器\n",
    "            r=r.find_all('p')\n",
    "            r='%s'*len(r) % tuple(r)\n",
    "            r=r.split('註冊')[1].split('案件編號')[0]\n",
    "            r=r.strip()\n",
    "            r1= re.compile(r'[<p> /] ')\n",
    "            r= r1.sub('' ,r )\n",
    "            return r\n",
    "        elif b=='13': #風傳媒\n",
    "            r=requests.get(a,verify=False,headers=headers)\n",
    "            r.encoding='utf-8'\n",
    "            r=BeautifulSoup(r.text,'lxml') #以lxml為解碼器\n",
    "            r=r.find_all('p')\n",
    "            r='%s'*len(r) % tuple(r)\n",
    "            r=r.split('</p><p aid=\"61\">')[1].split('喜歡這篇文章嗎？')[0]\n",
    "            r=r.strip()\n",
    "            r1= re.compile(r'[<p> /] ')\n",
    "            r= r1.sub('' ,r )\n",
    "            return r\n",
    "        elif b=='14': #oncc\n",
    "            r=requests.get(a,verify=False,headers=headers)\n",
    "            r.encoding='utf-8'\n",
    "            r=BeautifulSoup(r.text,'lxml') #以lxml為解碼器\n",
    "            r=r.find_all('p')\n",
    "            r='%s'*len(r) % tuple(r)\n",
    "            r=r.strip()\n",
    "            r1= re.compile(r'[<p> / br] ')\n",
    "            r= r1.sub('' ,r )\n",
    "            return r\n",
    "        elif b=='15': #ebc\n",
    "            r=requests.get(a,verify=False,headers=headers)\n",
    "            r.encoding='utf-8'\n",
    "            r=BeautifulSoup(r.text,'lxml') #以lxml為解碼器\n",
    "            r=r.find_all('p')\n",
    "            r='%s'*len(r) % tuple(r)\n",
    "            r=r.strip()\n",
    "            r1= re.compile(r'[<p> / br]')\n",
    "            r= r1.sub('' ,r )\n",
    "            return r\n",
    "        else:\n",
    "            r=requests.get(a,verify=False,headers=headers)\n",
    "            r.encoding='utf-8'\n",
    "            r=BeautifulSoup(r.text,'lxml') #以lxml為解碼器\n",
    "            r=r.find_all('p')\n",
    "            r='%s'*len(r) % tuple(r) \n",
    "            r=r.strip()\n",
    "            r1= re.compile(r'[<p> /]')\n",
    "            r= r1.sub('' ,r )\n",
    "            return r\n",
    "    else: return 'error' \n",
    "#div,p分流\n",
    "tab['result'] = tab.apply(lambda x: function(x.hyperlink,x.test1,x.test2), axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab.to_csv('jade_v2.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 以上程式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 調校區"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'result'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-e402f7631872>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m408\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5065\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5066\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5067\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5069\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'result'"
     ]
    }
   ],
   "source": [
    "a=tab.result[408]\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#爬文第一步&讓網站以為你是真人(User-agent的輸入)\n",
    "import requests\n",
    "from requests.packages import urllib3\n",
    "urllib3.disable_warnings()\n",
    "headers={\n",
    "    'User-agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36'\n",
    "}\n",
    "r=requests.get('https://www.businesstoday.com.tw/article/category/80401/post/201910010012/',verify=False,headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.encoding='utf-8'\n",
    "r=BeautifulSoup(r.text,'lxml') #以lxml為解碼器\n",
    "r=r.find_all('p')\n",
    "r='%s'*len(r) % tuple(r) \n",
    "r=r.strip()\n",
    "r1= re.compile(r'[<p> /]')\n",
    "r= r1.sub('' ,r )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "台中市台中市台中市鄭姓男子吸毒遭警方查獲供出上手是越南籍逃逸移工移工移工阮文全警方逮捕阮後又循線抓到印尼印尼印尼籍上游阿曼兩人均被檢方依毒品毒品毒品罪起訴台中地院認為兩人仗勢外籍移工身分在台灣販毒判阮三年十月徒刑阿曼四年四月徒刑宣告期滿驅逐出境判決指出鄭姓男子因涉毒品案遭警方逮捕向警方供出賣他毒品的是越南籍逃逸移工阮文全並同意配合辦案以手機與阮聯繫購買安毒阮信以為真再聯繫印尼籍上手阿曼阿曼將毒品交給阮後阮將毒品分裝十小包警方趁阮與鄭交易時當場人贓俱獲直售聯播阮被捕後向警方坦承毒品來源是阿曼警方今年六月分別在阿曼的南投住所與公司員工宿舍搜出安毒十一包並查扣分裝袋手機等物合議庭調查阮與阿曼兩人非至親不會花費心思規避查緝認定兩人購入的毒品價位比售出的價位還要低可預見兩人從中賺取差價不法牟利考量阮為越南籍逃逸移工阿曼為印尼籍合法移工兩人販毒危害國民健康與社會治安宣告執行期滿後驅逐出境\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "r=BeautifulSoup(r.text,'lxml') #以liml為解碼器\n",
    "r='%s'*len(r) % tuple(r)\n",
    "r=r.split('end of articles' )[0].split('<!-- content from cms -->')[1]\n",
    "r=r.strip()\n",
    "r=re.sub(r'[^\\u4e00-\\u9fa5]','',r)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-0d6c19f25485>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mbs4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'lxml'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#以liml為解碼器\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'p'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'%s'\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "r=BeautifulSoup(r.text,'lxml') #以liml為解碼器\n",
    "r=r.find_all('p')\n",
    "r='%s'*len(r) % tuple(r)\n",
    "r=r.split('</span>')[1].split('<p class=\"updated-time\">')[0]\n",
    "r1= re.compile(r'</p>')\n",
    "r= r1.sub('' , r)\n",
    "r1= re.compile(r'<p>')\n",
    "r= r1.sub('' , r)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "位於桃園市桃園區春日路的建案「銘曜高尚」近日驚傳建商落跑，留下鉅額債務給已購的買方，有消費者出面指控，建商一屋二賣，欺騙大眾，而記者致電銘耀建設負責人，電話號碼已經暫停使用。</p><p> </p><p>「銘曜高尚」鄰近家樂福春日店、Uniqlo，週邊生活機能完整，也有國中小學區，加上該案主打4米2+3米錯層式設計，小宅的價錢就可買到高坪效，因此吸引許多自住族青睞，而且成屋銷售，讓大家看得到摸得到，沒想到還是發生建商落跑憾事。</p><p> </p><p>觀察該案官方粉絲團，最新發文停留在去年12月21日，當時還舉行聖誕抽獎活動，完全看不出異樣。然而受害者出面指控，不僅「銘曜高尚」一屋二賣，另一個在桃園區泰昌街的案子也是同樣狀況。目前「銘曜高尚」大樓已經被受害者張貼「黑心建商」、「邱阿水聯合詐欺」等布條，據了解，建商超貸3億元，如果消費者想要過戶，必須得先償還債務塗銷貸款。</p><p> </p><p>據了解，此次是碁曜機構董事長邱水成及其妻子邱秀芬遭指控詐欺落跑，而該案「銘曜高尚」主要由兒子邱俊銘負責，如今父母疑似出事落跑，兒子手機也停話未回應，此外，據相關人士私下透露，邱水成女兒名下的擎亞建設似乎也出現倒閉危機。</p><p> </p><p>住展雜誌企研室經理何世昌指出，購買預售屋擁有相對風險，建議消費者在篩選建商時，除了建商至少要營運超過五年、手上建案10個以上，才能確保建商足夠的財力。\n"
     ]
    }
   ],
   "source": [
    "#自由時報內容\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "r.encoding='utf-8'\n",
    "r=BeautifulSoup(r.text,'lxml') #以liml為解碼器\n",
    "r=r.find_all('p')\n",
    "r='%s'*len(r) % tuple(r)\n",
    "r=r.split('</span></span></p><p>')[1].split('</p><p><span class=\"ph_b ph_d1\">')[0]\n",
    "r=re.sub(r'[^\\u4e00-u9fa5]','',r)\n",
    "print(r)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
